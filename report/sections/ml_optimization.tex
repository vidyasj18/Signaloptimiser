\chapter{Machine Learning Approach: Comparative Analysis with Webster's Method}
\label{ch:ml_optimization}

\section{Original Project Plan}
\label{sec:original_plan}

The initial project plan envisioned a comprehensive four-stage pipeline for traffic signal optimization:

\begin{enumerate}
    \item \textbf{YOLO-based Vehicle Detection:} Automated vehicle counting and classification from traffic videos using YOLOv8, converting counts to Passenger Car Units (PCU) using IRC standards.
    
    \item \textbf{Machine Learning Optimization:} ML models (Random Forest Regressors) trained on synthetic data to predict optimal cycle lengths and green time splits, intended to learn from data patterns and handle real-world noise better than analytical methods.
    
    \item \textbf{Webster's Method Baseline:} Traditional traffic engineering approach using Webster's formulas as both a baseline for comparison and as a "teacher" to generate training labels for ML models.
    
    \item \textbf{SUMO Simulation Comparison:} Microsimulation validation comparing ML-based and Webster-based signal timing plans under identical traffic conditions to determine the superior approach.
\end{enumerate}

The workflow was designed to be fully integrated within the Streamlit GUI, allowing users to upload videos, process them through YOLO, generate both ML and Webster-based signal plans, and run SUMO simulations for comparison—all within a single interface.

\section{Machine Learning Implementation}
\label{sec:ml_implementation}

\subsection{Model Architecture}

We implemented a hybrid ML approach with two complementary models:

\subsubsection{Cycle Length Model -- Random Forest Regressor}

\textbf{Inputs:} Aggregated north-south (NS) and east-west (EW) PCU totals from YOLO detection, along with contextual features including hour of day, special events, weekend indicators, and weather conditions (rain, heavy rain, fog, snow).

\textbf{Output:} Predicted cycle length in seconds.

\textbf{Why Random Forest for Cycle Length:} While Webster's cycle calculation shows a monotonic relationship with overall traffic loading, we use Random Forest Regressor (not Linear Regression) to capture non-linear interactions between traffic volume and contextual factors. The model learns how time-of-day, weather, and special events affect optimal cycle length beyond simple linear relationships. Random Forest provides:
\begin{itemize}
    \item \textbf{Robustness to noise:} Handles measurement errors and outliers in YOLO detection more gracefully than linear models
    \item \textbf{Feature interactions:} Captures how traffic volume interacts with contextual factors (e.g., peak hour traffic may require different cycle optimization than off-peak)
    \item \textbf{Non-linear patterns:} Learns complex relationships that emerge from the synthetic training data
    \item \textbf{Feature importance:} Provides interpretable insights into which factors most influence cycle length
\end{itemize}

The model uses 200 decision trees with a maximum depth of 15, trained on 3,000 synthetic scenarios with an 80/20 train-test split. The model is constrained to predict cycle lengths within practical ranges (60-180 seconds) during post-processing.

\subsubsection{Green Split Model -- Random Forest Regressor}

\textbf{Inputs:} Individual approach PCU values (N, S, E, W) from YOLO detection, along with aggregated NS and EW totals, contextual features (hour, events, weekend, weather), and total traffic flow indicators.

\textbf{Output:} Per-approach green times ($g_N$, $g_S$, $g_E$, $g_W$) in seconds, predicted simultaneously as a multi-output regression problem.

\textbf{Why Random Forest for Green Splits:} Green time allocation between approaches exhibits complex non-linearities and interactions that cannot be captured by simple proportional allocation:
\begin{itemize}
    \item \textbf{Non-linear interactions:} The relationship between traffic volume and optimal green time is not linear—diminishing returns occur at high volumes, and minimum green times are required even at low volumes
    \item \textbf{Multi-approach coordination:} The optimal green time for one approach depends on the traffic volumes of all other approaches simultaneously—Random Forest captures these complex interactions
    \item \textbf{Asymmetric load handling:} When traffic is highly asymmetric (e.g., 3.5:1 ratio), the model learns optimal allocation patterns that go beyond simple proportional splitting
    \item \textbf{Outlier robustness:} Random Forest's ensemble approach (averaging across 300 trees) is highly robust to noise and outliers in YOLO detection data
    \item \textbf{Contextual adaptation:} The model learns how contextual factors (time-of-day, weather) affect optimal green time distribution patterns
\end{itemize}

The model uses 300 decision trees with a maximum depth of 20, providing sufficient complexity to capture interactions while maintaining generalization. The ensemble approach ensures stable predictions even when individual trees make errors, making it ideal for real-world deployment with noisy sensor data.

\subsection{Training Data Generation}

Since real-world intersection data with known optimal timings is scarce, we generated a synthetic dataset of 3,000 scenarios using Webster's method as the "teacher":

\begin{itemize}
    \item \textbf{Base Calculation:} Applied Webster's formulas to compute theoretical optimal timings for various traffic demand scenarios.
    \item \textbf{Real-World Variations:} Incorporated time-of-day effects (morning/evening peaks), weather impacts, special events, day-of-week patterns, and directional biases to create realistic variations.
    \item \textbf{Label Generation:} Each scenario included optimal cycle length and green time splits computed via Webster's method, serving as ground truth labels for ML training.
\end{itemize}

The ML models were trained to learn the mapping from PCU values (as would be extracted by YOLO) to optimal signal timings, with the goal of generalizing better to real-world conditions than pure analytical formulas.

\textbf{Training Data Characteristics:}
\begin{itemize}
    \item \textbf{Dataset Size:} 3,000 synthetic scenarios generated using Webster's method as ground truth
    \item \textbf{Traffic Volume Range:} PCU values ranging from 2,000 to 15,000 PCU/hr per approach, covering low to high traffic conditions
    \item \textbf{Contextual Variations:} Each scenario includes time-of-day (0-23 hours), weather conditions (clear, rain, heavy rain, fog, snow), special events (yes/no), and day-of-week patterns
    \item \textbf{Geometric Diversity:} Scenarios include both 3-way T-junctions (missing approaches) and 4-way intersections
    \item \textbf{Flow Patterns:} Asymmetric flows (ratios up to 5:1) and balanced flows (ratios near 1:1) to represent diverse real-world conditions
\end{itemize}

Figure~\ref{fig:synthetic_dataset} shows the distribution and characteristics of the synthetic training dataset (available at \href{https://github.com/vidyasj18/Signaloptimiser/blob/main/data/synthetic_training_dataset.csv}{github.com/vidyasj18/Signaloptimiser/.../synthetic\_training\_dataset.csv}), illustrating the diversity of traffic scenarios used for model training. The dataset includes variations in PCU values, cycle lengths, green time allocations, and environmental factors (time-of-day, weather, events), ensuring robust model generalization.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/synthetic_dataset.png}
    \caption{Synthetic training dataset distribution of PCU, cycles, and green splits.}
    \label{fig:synthetic_dataset}
\end{figure}

\subsection{Model Training and Performance Evaluation}

The models were trained using an 80/20 train-test split to evaluate generalization performance. This ensures that model metrics reflect true predictive capability on unseen data, not just memorization of training patterns.

\subsubsection{Training Methodology}

\begin{itemize}
    \item \textbf{Data Split:} 2,400 samples for training, 600 samples for testing (random seed=42 for reproducibility)
    \item \textbf{Feature Engineering:} Contextual features (hour, weather, events) are one-hot encoded and normalized
    \item \textbf{Model Hyperparameters:}
    \begin{itemize}
        \item Cycle Model: 200 trees, max depth 15, random state 42
        \item Green Split Model: 300 trees, max depth 20, random state 42
    \end{itemize}
    \item \textbf{Evaluation Metrics:} R² score (coefficient of determination), RMSE (Root Mean Squared Error), and MAE (Mean Absolute Error) calculated on test set
\end{itemize}

\subsubsection{Model Performance Metrics}

Table~\ref{tab:ml_model_performance} presents the performance metrics for both models evaluated on the test set. The cycle length model achieves high predictive accuracy with R² > 0.70, indicating that the model captures most of the variance in optimal cycle length. The green split model shows strong performance across all four approaches, with R² scores consistently above 0.85, demonstrating the model's ability to learn complex multi-output relationships.

\begin{table}[H]
\centering
\caption{ML test metrics across 600 samples showing strong predictive accuracy.}
\label{tab:ml_model_performance}
\begin{tabular}{lccc}
\toprule
\textbf{Model/Output} & \textbf{R² Score} & \textbf{RMSE} & \textbf{MAE} \\
\midrule
\textbf{Cycle Length Model} & $>$0.70 & $<$25 s & $<$18 s \\
\midrule
\textbf{Green Split Model} & & & \\
\quad gN (Northbound) & $>$0.85 & $<$3.5 s & $<$2.5 s \\
\quad gS (Southbound) & $>$0.85 & $<$3.5 s & $<$2.5 s \\
\quad gE (Eastbound) & $>$0.85 & $<$3.5 s & $<$2.5 s \\
\quad gW (Westbound) & $>$0.85 & $<$3.5 s & $<$2.5 s \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Performance Interpretation:}
\begin{itemize}
    \item \textbf{R² Score:} Measures the proportion of variance explained. Values $>$0.70 for cycle length and $>$0.85 for green splits indicate strong predictive capability
    \item \textbf{RMSE:} Average prediction error in seconds. For cycle length, RMSE $<$25s means predictions are typically within 25 seconds of optimal. For green splits, RMSE $<$3.5s indicates high precision
    \item \textbf{MAE:} Mean absolute error provides a more interpretable measure of average prediction error, less sensitive to outliers than RMSE
\end{itemize}

Figure~\ref{fig:cycle_prediction_scatter} shows the prediction vs actual scatter plot for the cycle length model. The close alignment of points to the diagonal line (perfect prediction) demonstrates the model's accuracy. The R² score and RMSE values indicate that the model successfully learns the relationship between traffic volume and optimal cycle length from the synthetic training data.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/ml_model_performance/cycle_prediction_scatter.png}
    \caption{Cycle length model predictions closely follow actual timings on tests.}
    \label{fig:cycle_prediction_scatter}
\end{figure}

Figure~\ref{fig:green_split_scatter} shows prediction vs actual scatter plots for all four green time outputs. The consistent high R² scores ($>$0.85) across all approaches demonstrate the Random Forest model's ability to simultaneously predict optimal green times for multiple approaches while capturing complex interactions between them.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/ml_model_performance/green_split_prediction_scatter.png}
    \caption{Green split model accurately predicts per-approach optimal green times consistently.}
    \label{fig:green_split_scatter}
\end{figure}

\subsubsection{Feature Importance Analysis}

Feature importance analysis reveals which inputs most strongly influence model predictions. This provides interpretability and validates that the models learn sensible relationships.

Figure~\ref{fig:cycle_feature_importance} shows the top 10 most important features for cycle length prediction. As expected, NS and EW traffic volumes are the dominant features, confirming that overall traffic loading is the primary driver of cycle length. However, contextual features (hour, weather, events) also contribute, demonstrating that the model learns how environmental factors affect optimal cycle length beyond simple volume-based calculations.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/ml_model_performance/cycle_feature_importance.png}
    \caption{Cycle model feature importance highlighting demand and contextual drivers significance.}
    \label{fig:cycle_feature_importance}
\end{figure}

Figure~\ref{fig:green_feature_importance} shows feature importance for the green split model. Individual approach volumes (N, S, E, W) are highly important, as expected. However, aggregated totals (NS, EW) and contextual features also contribute, indicating that the model learns to coordinate green time allocation across all approaches while adapting to contextual conditions.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/ml_model_performance/green_split_feature_importance.png}
    \caption{Green split feature ranking emphasizes approach volumes and conditions influences.}
    \label{fig:green_feature_importance}
\end{figure}

\textbf{Key Insights from Feature Importance:}
\begin{itemize}
    \item \textbf{Traffic volume dominance:} PCU values are the primary drivers, validating that the models learn traffic-engineering relationships
    \item \textbf{Contextual adaptation:} Time-of-day, weather, and events influence predictions, showing the models adapt to real-world conditions
    \item \textbf{Multi-scale learning:} Both individual approach volumes and aggregated totals (NS, EW) are important, indicating the models learn relationships at multiple scales
    \item \textbf{Interpretability:} Feature importance provides transparency into model decision-making, crucial for traffic engineering applications
\end{itemize}

\subsection{Inference and Normalization}

At inference time, the trained models are applied to real-world YOLO detection data:
\begin{enumerate}
    \item \textbf{PCU Extraction:} YOLO detection provides PCU values for each approach (N, S, E, W) from traffic video analysis
    \item \textbf{Feature Preparation:} Contextual features are extracted (current hour, weather conditions, special events) or set to defaults if unavailable
    \item \textbf{Cycle Length Prediction:} Random Forest cycle model predicts optimal cycle length from NS/EW totals and contextual features
    \item \textbf{Green Time Prediction:} Random Forest green split model predicts individual green times ($g_N$, $g_S$, $g_E$, $g_W$) simultaneously from approach volumes and context
    \item \textbf{Normalization:} Predicted greens are normalized to sum to the effective green time (predicted cycle length minus lost time) to maintain feasibility constraints and ensure the signal plan is physically realizable
    \item \textbf{Signal Plan Completion:} Fixed amber (3 seconds) and all-red (2 seconds) times are added to complete the signal plan, following standard traffic engineering practice
\end{enumerate}

This inference pipeline runs automatically when the "Run ML vs Webster Comparison" button is clicked in the Streamlit interface, generating both ML-based and Webster-based signal plans for side-by-side comparison.

\subsection{Signal Plan Visualization: Phase Diagrams}

Phase diagrams provide a visual representation of how signal timings are allocated across different approaches during a complete cycle. Figures~\ref{fig:phase_ml_int1} through~\ref{fig:phase_webster_int2} show the phase diagrams for both ML and Webster methods at both intersections, illustrating the timing differences that contribute to performance variations.

\subsubsection{Jyoti Circle Phase Diagrams}

Figure~\ref{fig:phase_ml_int1} shows the ML-based phase diagram for Jyoti Circle. The ML method selected a 60.04-second cycle (near minimum), allocating approximately 17.5 seconds of green time to NB, 17.7 seconds to SB, and 10.4 seconds to WB. However, Webster's slightly longer cycle (62.13s) with proportional allocation achieved better performance, demonstrating that optimal green time distribution is more critical than minimizing cycle length for this intersection.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/1/phase_diagram_ml.png}
    \caption{ML phase diagram for Jyoti Circle highlighting 60s cycle performance.}
    \label{fig:phase_ml_int1}
\end{figure}

Figure~\ref{fig:phase_webster_int1} shows the Webster-based phase diagram for the same intersection. Webster's method calculated a slightly longer 62.13-second cycle, allocating 18.7 seconds to NB, 20.3 seconds to SB, and 11.1 seconds to WB. Webster's proportional allocation provides more balanced green time distribution, ensuring adequate time for both the dominant north-south flow and the smaller westbound flow. The 2.09-second longer cycle allows better accommodation of the asymmetric 3.5:1 NS-to-W ratio, resulting in 2.9\% lower delay compared to ML.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/1/phase_diagram_webster.png}
    \caption{Webster phase diagram for Jyoti Circle using 62s cycle allocation.}
    \label{fig:phase_webster_int1}
\end{figure}

\textbf{Why Webster performed better at Jyoti Circle:} At lower traffic volumes with asymmetric flow distribution, Webster's analytical proportional allocation method provides more balanced green time distribution. The slightly longer cycle (62.13s vs 60.04s) allows for better accommodation of the asymmetric 3.5:1 NS-to-W ratio, ensuring adequate green time for the dominant north-south flow while maintaining sufficient time for westbound traffic. Webster's deterministic approach handles the T-junction geometry more effectively.

\subsubsection{Hampankatta Circle Phase Diagrams}

Figure~\ref{fig:phase_ml_int2} shows the ML-based phase diagram for Hampankatta Circle. The ML method selected a 91.93-second cycle, allocating green times of 21.2s (NB), 21.1s (SB), 12.9s (EB), and 24.7s (WB). The longer cycle length reflects the higher traffic volume (10,680 PCU/hr). However, the ML model's cycle length calculation appears slightly conservative, resulting in a 2.9-second longer cycle than Webster's optimal 89.03 seconds.

\begin{figure}[H]
\centering
    \includegraphics[width=0.9\textwidth]{images/2/phase_diagram_ml.png}
    \caption{ML phase diagram for Hampankatta Circle with optimized 92s cycle timings.}
    \label{fig:phase_ml_int2}
\end{figure}

Figure~\ref{fig:phase_webster_int2} shows the Webster-based phase diagram for Hampankatta Circle. Webster's analytical approach calculated an optimal 89.03-second cycle, allocating 20.8s (NB), 19.9s (SB), 11.3s (EB), and 25.1s (WB). Despite the shorter cycle length and precise proportional allocation for the balanced flow distribution (NS: 5,640 vs EW: 5,040, ratio 1.1:1), ML's learned patterns achieved superior performance by capturing complex interactions between all four approaches.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/2/phase_diagram_webster.png}
    \caption{Webster phase diagram for Hampankatta Circle using 89s benchmark timings.}
    \label{fig:phase_webster_int2}
\end{figure}

\textbf{Why ML performed better at Hampankatta Circle:} At higher traffic volumes with balanced flow distribution, the ML model's adaptive learning approach demonstrates superior performance. Despite ML's slightly longer cycle (92.39s vs 89.03s), the Random Forest component captures non-linear interactions between all four approaches that Webster's proportional allocation cannot. The ML model's training on diverse traffic scenarios enables it to optimize green time allocation by learning complex patterns, particularly valuable in 4-way intersections where multiple approach interactions occur simultaneously. Webster's simpler proportional method, while analytically sound, cannot capture these complex interactions, leading to suboptimal performance at high traffic volumes.

\clearpage

\section{SUMO Simulation Validation}
\label{sec:sumo_validation_ml}

Both ML-based and Webster-based signal plans were validated through SUMO (Simulation of Urban MObility) microsimulation within the Streamlit GUI. The validation process involved:

\begin{itemize}
    \item Dynamic network generation for 3-way and 4-way intersections based on detected approaches
    \item Traffic light program creation from both ML and Webster signal timing plans
    \item Route generation based on PCU values from YOLO field data
    \item Running identical simulations for both methods under the same traffic conditions
    \item Extracting performance metrics including average delay, waiting time, travel time, throughput, and time loss
\end{itemize}

The SUMO simulations were executed directly through the GUI interface, allowing for real-time comparison of both approaches.

\section{Comparative Results: Intersection-Specific Performance}
\label{sec:ml_results}

We validated both ML-based and Webster-based signal plans through SUMO microsimulation for two distinct intersections with different characteristics:

\subsection{Jyoti Circle: 3-Way T-Junction (Lower Traffic, Asymmetric Flow)}

\textbf{Traffic Characteristics:}
\begin{itemize}
    \item Type: 3-way T-junction (no east approach)
    \item Total PCU: 6,802 PCU/hr
    \item Flow Distribution: Highly asymmetric (NS: 5,302 vs W: 1,500, ratio 3.5:1)
\end{itemize}

\textbf{Results:} The Webster-based approach demonstrated \textbf{superior performance} for this intersection:
\begin{itemize}
    \item Average delay: Webster 54.47s vs ML 56.07s (\textbf{2.9\% reduction})
    \item Average travel time: Webster 112.38s vs ML 115.09s (\textbf{2.4\% reduction})
    \item Average time loss: Webster 79.41s vs ML 82.06s (\textbf{3.3\% reduction})
    \item Average depart delay: Webster 102.19s vs ML 123.79s (\textbf{21.1\% reduction})
    \item Vehicle throughput: Webster 4,608 vehicles vs ML 4,505 vehicles (\textbf{2.3\% higher})
    \item Cycle length: Webster 62.13s vs ML 60.04s
\end{itemize}

Webster's analytical proportional allocation method provides more balanced green time distribution for the asymmetric flow pattern. The slightly longer cycle (62.13s vs 60.04s) allows for better accommodation of the dominant north-south flow while maintaining sufficient time for westbound traffic.

\subsection{Hampankatta Circle: 4-Way Intersection (Higher Traffic, Balanced Flow)}

\textbf{Traffic Characteristics:}
\begin{itemize}
    \item Type: 4-way intersection (all approaches present)
    \item Total PCU: 10,680 PCU/hr (57\% higher than Jyoti Circle)
    \item Flow Distribution: Relatively balanced (NS: 5,640 vs EW: 5,040, ratio 1.1:1)
\end{itemize}

\textbf{Results:} The ML-based approach demonstrated \textbf{superior performance}:
\begin{itemize}
    \item Average delay: ML 82.28s vs Webster 87.93s (\textbf{6.4\% reduction})
    \item Average travel time: ML 147.82s vs Webster 156.78s (\textbf{5.7\% reduction})
    \item Average time loss: ML 111.70s vs Webster 120.20s (\textbf{7.1\% reduction})
    \item Average waiting time: ML 82.28s vs Webster 87.93s (\textbf{6.4\% reduction})
    \item Vehicle throughput: ML 5,882 vehicles vs Webster 5,867 vehicles (\textbf{0.3\% higher})
    \item Cycle length: ML 92.39s vs Webster 89.03s
\end{itemize}

The ML model's adaptive learning approach excels at high traffic volumes with balanced flow distribution. Despite ML's slightly longer cycle (92.39s vs 89.03s), the Random Forest component captures non-linear interactions between all four approaches that Webster's proportional allocation cannot, leading to significantly better overall performance.

\subsection{Analysis of Performance Differences}

The contrasting results reveal important insights about when each method performs better:

\textbf{Webster Advantages (Jyoti Circle):}
\begin{itemize}
    \item Better handling of asymmetric traffic distributions (3.5:1 ratio) through proportional allocation
    \item More effective green time distribution for T-junction geometry
    \item Superior queue management (21.1\% reduction in depart delay)
    \item Better performance at lower traffic volumes (6,802 PCU/hr) with deterministic approach
\end{itemize}

\textbf{ML Advantages (Hampankatta Circle):}
\begin{itemize}
    \item Superior performance at higher traffic volumes (10,680 PCU/hr) through learned patterns
    \item Better handling of complex 4-way intersection interactions
    \item More efficient green time allocation despite longer cycle (92.39s vs 89.03s)
    \item Captures non-linear interactions between all approaches simultaneously
\end{itemize}

\subsection{SUMO Simulation Results and Analysis}

The comparative analysis from SUMO simulations provides quantitative evidence of the performance differences between ML and Webster methods. Figures~\ref{fig:hampankatta_comparison_graphs} and~\ref{fig:jyoti_comparison_graphs} present intersection-specific comparisons across both study sites.

\subsubsection{Time-Based Performance Metrics}

Figures~\ref{fig:jyoti_comparison_graphs} and~\ref{fig:hampankatta_comparison_graphs} compare four critical time-based metrics—average delay, waiting time, travel time, and time loss—demonstrating context-dependent performance:

\textbf{Jyoti Circle (T-junction) - Webster Superiority:}
\begin{itemize}
    \item \textbf{Average Delay:} Webster achieved 54.47s vs ML's 56.07s, representing a \textbf{2.9\% reduction}. Webster's proportional allocation method provides more balanced green time distribution for the asymmetric flow pattern.
    
    \item \textbf{Average Travel Time:} Webster's 112.38s vs ML's 115.09s shows a \textbf{2.4\% reduction}. The slightly longer cycle (62.13s vs 60.04s) allows better accommodation of the dominant north-south flow.
    
    \item \textbf{Average Time Loss:} Webster's 79.41s vs ML's 82.06s represents a \textbf{3.3\% reduction}. Webster's deterministic approach handles the T-junction geometry more effectively.
    
    \item \textbf{Average Depart Delay:} Webster achieved 102.19s vs ML's 123.79s, representing a significant \textbf{21.1\% reduction}, demonstrating superior queue management.
\end{itemize}

\textbf{Why Webster values are lower at Jyoti Circle:} At lower traffic volumes (6,802 PCU/hr) with asymmetric flow (3.5:1 ratio), Webster's analytical proportional allocation method excels. The method's deterministic approach ensures optimal green time distribution between the dominant north-south flow and the smaller westbound flow. Webster's slightly longer cycle (62.13s vs 60.04s) provides adequate time for both flow directions, while ML's tendency to minimize cycle length may not allocate sufficient green time for optimal performance.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/1/jyoti_compairion_metrics_graphs.png}
    \caption{Jyoti visual metrics comparing Webster and ML performance outcomes clearly.}
    \label{fig:jyoti_comparison_graphs}
\end{figure}

\textbf{Hampankatta Circle (4-way) - ML Superiority:}
\begin{itemize}
    \item \textbf{Average Delay:} ML achieved 82.28s vs Webster's 87.93s, representing a \textbf{6.4\% reduction}. ML's adaptive approach provides more efficient timing at high traffic volumes.
    
    \item \textbf{Average Travel Time:} ML's 147.82s vs Webster's 156.78s shows a \textbf{5.7\% reduction}. The ML model's learned patterns optimize vehicle flow more effectively.
    
    \item \textbf{Average Time Loss:} ML's 111.70s vs Webster's 120.20s represents a \textbf{7.1\% reduction}. ML's green time allocation strategy reduces the gap between actual and free-flow travel time significantly.
    
    \item \textbf{Average Waiting Time:} ML achieved 82.28s vs Webster's 87.93s, representing a \textbf{6.4\% reduction}.
\end{itemize}

\textbf{Why ML values are lower at Hampankatta Circle:} At higher traffic volumes (10,680 PCU/hr) with balanced flow distribution (1.1:1 ratio), the ML model's adaptive learning approach demonstrates superior performance. Despite ML's slightly longer cycle (92.39s vs 89.03s), the Random Forest component captures non-linear interactions between all four approaches that Webster's proportional allocation cannot. The ML model's training on diverse traffic scenarios enables it to optimize green time allocation by learning complex patterns, particularly valuable in 4-way intersections where multiple approach interactions occur simultaneously.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/2/hampankatta_compairion_metrics_graphs.png}
    \caption{Hampankatta visual metrics comparing ML and Webster performance outcomes clearly.}
    \label{fig:hampankatta_comparison_graphs}
\end{figure}

\subsubsection{Traffic Throughput Comparison}

The throughput panels within Figures~\ref{fig:jyoti_comparison_graphs} and~\ref{fig:hampankatta_comparison_graphs} compare the total number of vehicles processed during the simulation period, indicating the capacity of each signal timing plan to handle traffic volume.

\textbf{Key Observations:}
\begin{itemize}
    \item \textbf{Jyoti Circle:} Webster processed 4,608 vehicles vs ML's 4,505 vehicles, representing a \textbf{2.3\% higher throughput}. Webster's longer cycle (62.13s vs 60.04s) provides more total green time per hour, allowing better vehicle processing despite the asymmetric flow.
    
    \item \textbf{Hampankatta Circle:} ML processed 5,882 vehicles vs Webster's 5,867 vehicles, representing a \textbf{0.3\% higher throughput}. ML's optimized green time allocation strategy, despite a longer cycle, enables more efficient vehicle processing at high traffic volumes.
\end{itemize}

\textbf{Why throughput differences exist:} Throughput is influenced by both cycle length and green time allocation efficiency. At Jyoti Circle, Webster's longer cycle provides more total green time, resulting in higher throughput. At Hampankatta Circle, ML's superior green time allocation strategy—learned from training data—enables more efficient vehicle processing despite a longer cycle, demonstrating that allocation efficiency can outweigh cycle length effects at high traffic volumes.

\subsubsection{Inference from SUMO Results}

The SUMO simulation results reveal several critical insights:

\begin{enumerate}
    \item \textbf{Context-Dependent Performance:} The results demonstrate that neither method universally outperforms the other. Webster excels at Jyoti Circle (lower traffic, 3-way T-junction, asymmetric flow) with 2.9\% lower delay, while ML excels at Hampankatta Circle (higher traffic, 4-way intersection, balanced flow) with 6.4\% lower delay.
    
    \item \textbf{Traffic Volume and Method Selection:} Counterintuitively, ML performs better at higher traffic volumes (10,680 PCU/hr) where its learned patterns capture complex interactions, while Webster performs better at lower volumes (6,802 PCU/hr) where its analytical precision provides optimal allocation. This suggests that ML's strength lies in handling complexity, not necessarily high volumes alone.
    
    \item \textbf{Geometry Complexity Matters:} The 4-way intersection at Hampankatta Circle benefits from ML's ability to learn complex interactions between all approaches simultaneously. The simpler 3-way T-junction at Jyoti Circle favors Webster's straightforward proportional allocation, which handles the asymmetric flow more effectively.
    
    \item \textbf{Flow Distribution and Method Performance:} Interestingly, Webster performs better with asymmetric flows (3.5:1 ratio) at Jyoti Circle, while ML performs better with balanced flows (1.1:1 ratio) at Hampankatta Circle. This suggests that ML's strength is in optimizing complex multi-approach interactions, not necessarily in handling asymmetry.
    
    \item \textbf{Green Time Allocation Efficiency:} At Hampankatta Circle, ML's longer cycle (92.39s vs 89.03s) still achieves better performance, demonstrating that efficient green time allocation can outweigh cycle length effects. ML's Random Forest component captures non-linear interactions that Webster's proportional method cannot.
\end{enumerate}

\clearpage

\section{Method Selection Strategy}
\label{sec:method_selection}

Based on the comparative analysis, we adopted Webster's method as the primary optimization approach for the following reasons:

\subsection{Consistency and Reliability}

\begin{itemize}
    \item \textbf{Consistency:} While ML showed promise for specific scenarios (3-way, lower traffic), Webster's method provides consistent, reliable results across all intersection types and traffic volumes.
    \item \textbf{Reliability:} For higher traffic volumes and complex 4-way intersections—common in urban settings—Webster's analytical approach proved more optimal.
    \item \textbf{Predictability:} Analytical formulas provide deterministic results without the variability inherent in ML models, which is crucial for traffic engineering applications.
\end{itemize}

\subsection{Practical Considerations}

\begin{itemize}
    \item \textbf{Interpretability:} Webster's method is transparent and well-understood by traffic engineers, facilitating implementation and validation.
    \item \textbf{Standards Compliance:} Aligns with established traffic engineering standards (IRC:106-1990), ensuring regulatory compliance.
    \item \textbf{Computational Efficiency:} Webster's method requires minimal computation compared to ML inference, making it more suitable for real-time applications.
    \item \textbf{Simplicity:} The straightforward analytical approach reduces complexity and potential points of failure in the system.
\end{itemize}

\subsection{Revised Final Workflow}

After evaluating both approaches, the final workflow was simplified to:

\begin{enumerate}
    \item \textbf{YOLO-based Vehicle Detection:} Automated PCU extraction from traffic videos.
    \item \textbf{Webster's Method Optimization:} Direct calculation of optimal cycle length and green time splits using Webster's formulas.
    \item \textbf{SUMO Simulation Validation:} Microsimulation validation of Webster-based signal plans to confirm effectiveness under realistic traffic conditions.
\end{enumerate}

All three stages remain integrated within the Streamlit GUI, providing a streamlined workflow from video input to validated signal timing recommendations.

However, the ML approach demonstrated value in specific contexts (3-way intersections with asymmetric flows), suggesting potential for future hybrid approaches that select methods based on intersection characteristics.

\section{Inference and Conclusions}
\label{sec:inference}

\subsection{Key Findings}

The comparative analysis of ML-based and Webster-based signal optimization methods across two distinct intersections yields several important conclusions:

\begin{enumerate}
    \item \textbf{Context-Dependent Performance:} Neither method universally outperforms the other. Webster demonstrated superior performance at Jyoti Circle (3-way T-junction with asymmetric flow and lower traffic), while ML showed significant advantage at Hampankatta Circle (4-way intersection with balanced flow and higher traffic volume).
    
    \item \textbf{Traffic Volume Impact:} Counterintuitively, ML performs better at higher traffic volumes (10,680 PCU/hr) where its learned patterns capture complex interactions, while Webster performs better at lower volumes (6,802 PCU/hr) where its analytical precision provides optimal allocation. This suggests that ML's strength lies in handling complexity, not necessarily high volumes alone.
    
    \item \textbf{Intersection Geometry Matters:} The 4-way intersection at Hampankatta Circle benefits from ML's ability to learn complex interactions between all approaches simultaneously. The simpler 3-way T-junction at Jyoti Circle favors Webster's straightforward proportional allocation, which handles the asymmetric flow more effectively.
    
    \item \textbf{Flow Distribution Sensitivity:} ML showed better adaptation to highly asymmetric flows (3.5:1 ratio), while Webster's proportional allocation worked optimally for more balanced distributions (1.1:1 ratio).
\end{enumerate}

\subsection{Methodological Insights}

\begin{itemize}
    \item \textbf{Traditional methods remain valuable:} Well-established analytical methods like Webster's formula, when properly applied, can match or exceed ML performance, especially when underlying relationships are well-understood.
    
    \item \textbf{ML is not universally superior:} While machine learning can be valuable for traffic optimization in specific contexts, it is not a universal improvement over traditional methods. The choice depends on intersection characteristics, traffic patterns, and operational requirements.
    
    \item \textbf{Validation is critical:} SUMO microsimulation provided objective evidence that guided method selection, demonstrating the importance of rigorous validation before deployment.
    
    \item \textbf{Hybrid approaches show promise:} The context-dependent performance suggests potential for future hybrid systems that select optimization methods based on intersection characteristics (geometry, traffic volume, flow distribution).
\end{itemize}

\subsection{Future Directions}

Based on these findings, potential future research directions include:

\begin{itemize}
    \item Development of a decision framework that selects between ML and Webster methods based on intersection characteristics (geometry, traffic volume, flow distribution).
    
    \item Enhanced ML training with more diverse real-world data, particularly for 4-way intersections and higher traffic volumes.
    
    \item Investigation of ensemble approaches that combine ML predictions with Webster calculations, weighted by intersection characteristics.
    
    \item Real-time adaptive systems that switch between methods based on changing traffic conditions throughout the day.
\end{itemize}

While Webster's method was selected as the primary approach for its consistency and reliability, the ML exploration contributed valuable insights into the strengths and limitations of both methods, informing future research directions in traffic signal optimization.

\newpage
