# Signal Optimiser (YOLO → PSU → Timings)

This project converts approach traffic from videos into Passenger Car Units (PSU) and produces fixed‑time signal plans using a Webster‑style method, ending with an exclusive phase timeline (NS vs EW) per cycle.

## Flow
- Detect and count vehicles per approach with the Streamlit app (`main.py`) using YOLOv8 + tracking and a virtual stopline (inbound only).
- Export approach totals and total PCU per approach to `outputs/intersection_summary.json` (and CSV).
- Compute timings and draw a phase diagram with `final.py` (reads the JSON automatically).

## Methodology
- Counting
  - YOLOv8 detections filtered by class (car, truck, bus, motorcycle, bicycle).
  - Lightweight tracker avoids double counting; virtual stopline counts only inbound crossings; optional ROI mask.
  - PCU factors (IRC‑style defaults): car=1.0, truck=3.0, bus=3.0, motorcycle=0.5, bicycle=0.5; Total PCU is sum(count × factor).
- Timings (Webster‑style)
  - Degree of saturation: Y = total_flow / capacity, capped at 0.95; capacity = (#present approaches × lanes × sat_per_lane).
  - Cycle: C = (1.5×lost_time + 5) / (1 − Y), clamped to [60, 180] s.
  - Effective green: G_eff = C − lost_time; split between NS and EW by demand share; then proportional split to approaches within each group.
  - Amber (yellow) and all‑red: constants applied per phase; timeline is exclusive (when NS is green/amber, EW is red; vice‑versa).

## How YOLO works (in this project)
- Frame‑level detection: YOLOv8 runs on each frame, returning bounding boxes, class labels, and confidences for road users (car, truck, bus, motorcycle, bicycle).
- Tracking and de‑duplication: lightweight association (distance/IoU) links boxes across frames into tracks; a min‑frames threshold filters out spurious hits.
- Inbound counting with a virtual stopline: a track is counted once, only when it crosses the user‑defined line in the inbound direction (with tolerance for near‑line motion). Optional ROI masks restrict detections to the inbound carriageway.
- PCU computation: approach totals = Σ(count[class] × PCU_factor[class]) with IRC‑style defaults; saved into `outputs/intersection_summary.json`.

## Why add ML on top of Webster (and what exactly we use)
We keep Webster for structure, but use ML to regularize and stabilize outputs in the presence of real‑world noise and partial coverage.

- Cycle length model — Linear Regression
  - Inputs: (`NS`, `EW`) totals; Output: cycle length.
  - Rationale: Webster's cycle is monotonic in the overall loading. A linear regressor provides an interpretable, low‑variance fit that closely matches the synthetic Webster mapping while tolerating small measurement noise. It's easy to clamp to [60, 180] s and inspect coefficients.
  - Benefits: interpretable, fast, and sufficient because the mapping from aggregate load to cycle is close to linear in the operational range after clamping and capping Y.

- Green split model — RandomForestRegressor (ensemble of decision trees)
  - Inputs: (`N`, `S`, `E`, `W`); Output: per‑approach green seconds (`gN`, `gS`, `gE`, `gW`).
  - Rationale: Splitting greens between approaches can have mild nonlinearities (e.g., diminishing returns, asymmetric sharing in noisy detections). A Random Forest captures interactions and outliers better than a pure linear rule, without heavy hyper‑parameter tuning.
  - Training: synthetic “teacher” labels are generated by Webster proportional splits (data augmentation across a wide demand range). The forest is then normalized at inference so Σgreens ≈ effective green (C − lost_time), preserving feasibility.
  - Benefits: robust to jitter/outliers in detections, handles asymmetric loads gracefully, and remains stable under noise; easy to retrain if you collect local data.

Why not only Webster? Pure Webster expects clean inputs and exact phase rules; real detections are imperfect (occlusion, partial views, varying speeds). The ML layer smooths and regularizes outputs to be more field‑friendly while keeping Webster's structure and a clear fallback.

## Webster + ML: how they fit together
- Teacher (Webster): We generate many synthetic traffic scenarios (N,S,E,W) and compute “ideal” labels using Webster's proportional splits and cycle formula. This encodes accepted traffic‑engineering behavior.
- Student (ML):
  - Linear Regression learns a simple mapping from (NS, EW) → cycle, close to Webster's relationship in the operating range.
  - RandomForest learns a robust mapping from (N, S, E, W) → (gN, gS, gE, gW), capturing mild nonlinearities and being resilient to noise.
- Inference time: We predict cycle and greens with ML, then normalize greens to the effective green (C − lost_time) to maintain feasibility, and finally apply fixed Amber and All‑red.

## ML terms in brief
- Linear Regression
  - A parametric model that fits a straight‑line relationship between inputs and a continuous output.
  - Here: predicts cycle length from (NS, EW). Chosen for interpretability, speed, and because Webster's cycle vs load is nearly linear after capping/clamping.
  - Pros: simple, transparent coefficients; Cons: limited to linear trends (mitigated by clamping and the forest handling splits).
- RandomForestRegressor
  - An ensemble of decision trees trained on bootstrapped samples; predictions are averaged across trees.
  - Here: predicts per‑approach green seconds from (N, S, E, W). Chosen for robustness to outliers/jitter, ability to model interactions and mild nonlinearities, and low tuning cost.
  - Pros: good default performance, handles noise well; Cons: less directly interpretable than a single linear model (we retain interpretability via Webster normalization and clear constraints).

## Inputs
- Videos: 3-4 approach videos (NB/SB/EB/WB). If only 3 are available (T‑junction), the pipeline adapts automatically.
- JSON produced by the app:
  - `outputs/intersection_summary.json` with keys NB/SB/EB/WB, each containing `total_pcu` and `vehicle_counts`.

## Outputs
- Per‑approach CSVs: `outputs/<APPROACH>_summary.csv` (counts, PCU by type, totals).
- Combined JSON/CSV: `outputs/intersection_summary.json` and `outputs/intersection_summary.csv` (approach totals).
- Timings and diagram: running `python final.py` prints per‑approach Green/Amber/Red and renders a horizontal exclusive phase timeline (NS vs EW) with all‑red.
- Signal plans: `outputs/ml_signal_plan.json` (ML-based) and `outputs/webster_signal_plan.json` (Webster-based).
- Comparison results: `outputs/signalplan_comparision.json` (performance metrics comparison).
- SUMO simulation: `outputs/sumo_comparison.json` (microsimulation validation results).
- Visualizations: `outputs/visualizations/` (all PNG charts and synthetic dataset CSV for report).

### Example: YOLO/app JSON (outputs/intersection_summary.json)
```json
{
  "NB": {"vehicle_counts": {"car": 120, "truck": 8, "bus": 5, "motorcycle": 60, "bicycle": 10}, "total_pcu": 194.0, "duration": 600.0},
  "SB": {"vehicle_counts": {"car": 100, "truck": 6, "bus": 4, "motorcycle": 55, "bicycle": 8},  "total_pcu": 161.5, "duration": 600.0},
  "EB": {"vehicle_counts": {"car": 150, "truck": 10, "bus": 6, "motorcycle": 80, "bicycle": 12}, "total_pcu": 244.0, "duration": 600.0},
  "WB": {"vehicle_counts": {"car": 130, "truck": 7, "bus": 5, "motorcycle": 70, "bicycle": 9},  "total_pcu": 205.5, "duration": 600.0}
}
```

### Example: final.py text output (Webster+ML)
```
=== Inputs (PSU) ===
{'N': 194.0, 'S': 161.5, 'E': 244.0, 'W': 205.5}

=== Predicted Cycle ===
92.40 s

=== Per-approach timings (s) ===
NB: green=18.85, amber=3.00, red=70.55
SB: green=15.69, amber=3.00, red=73.71
EB: green=26.17, amber=3.00, red=63.23
WB: green=20.69, amber=3.00, red=68.71

# A phase timeline plot (NS vs EW, exclusive with all-red) is displayed.
```

## How to run
```bash
# Create and activate venv (Windows shown)
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt

# 1) Count vehicles and generate JSON
streamlit run main.py
# Upload approach videos, set stoplines (use preview), process; or use Batch to process 3-4 together

# 2) Compute timings and show diagram
python final.py

# 3) Compare with Webster method
python webster.py
python compare_signal_plans.py

# 4) Run SUMO simulation
python sumo_simulation.py

# 5) Generate all visualizations for report (PNG images + CSV dataset)
# NEW: This script now runs steps 2-5 automatically! Just run:
python generate_visualizations.py
# It will execute final.py, webster.py, compare_signal_plans.py, sumo_simulation.py,
# and generate all visualizations in one go.
```

## Parameters (defaults)
- DEFAULT_LANES = 2 (lanes/approach; used in capacity; can be tuned or made per‑approach)
- SAT_PER_LANE = 1800 PCU/hr/lane (typical design value; calibrate locally)
- DEFAULT_LOST_TIME = 12 s (startup + change intervals)
- YELLOW (Amber) = 3 s; ALL_RED = 2 s

## Sources (IRC/Practice)
- IRC:106 — Guidelines for Capacity of Urban Roads in Plain Areas
- IRC:SP:41 — Guidelines for the Design of At‑Grade Intersections
- IRC:SP:90 — Manual on Road Traffic Signal Control
- Webster, F.V. — Traffic Signal Settings (TRRL)

Use site‑specific calibrations for saturation flow, lost time, amber/all‑red per local standards and the above IRC manuals.

## Challenges and mitigations
- Mixed camera geometry: use the preview to place the stopline where inbound vehicles cross; invert direction if counts are zero.
- Detections without crossings: increase crossing tolerance or lower minimum normal motion; remove masks to sanity‑check.
- Partial coverage (3 videos): JSON omits missing approach; `final.py` adapts to present approaches automatically (T‑junctions).
- Performance on long videos: process subsets (frame range in UI) and test with short clips first.

